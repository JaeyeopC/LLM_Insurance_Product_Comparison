{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General work flow with LangChain \n",
    "- [LangChain Guide Reference](https://python.langchain.com/docs/how_to/#output-parsers)  \n",
    "    1. Search: Query to url (e.g., using GoogleSearchAPIWrapper)   \n",
    "    2. [Document Loader](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/): load data from various sources(web sites, databases, YouTube, arXiv) of various types(PDF, HTML, Json, PowerPoint, etc) as a list of [```document objects```](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)  \n",
    "        - Example: [AsyncChromiumLoader](https://python.langchain.com/docs/integrations/document_loaders/async_chromium/) / [AyncHtmlLoader](https://python.langchain.com/docs/integrations/document_loaders/async_html/) - lightweight, load raw HTML files from a list of URLs concurrently\n",
    "        - Possibly substitue current crawler and transformer to make use of meta data of documents ( read [HTML Loader](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/html/), see also [Sementic Chunker : Langchain - How to split text based on semantic similarity](https://python.langchain.com/docs/how_to/semantic-chunker/) ) :  \n",
    "            - spider crawler, FireCrawl(Subpage serach, markdown output ), AzureAIDocumentIntelligenceLoader(different file format supports) \n",
    "    3. [Transformer](https://python.langchain.com/docs/integrations/document_transformers/)\n",
    "        - Example) [HTML2Text](https://python.langchain.com/v0.1/docs/integrations/document_transformers/html2text/) : HTML2Text provides a straightforward conversion of HTML content into plain text (with markdown-like formatting) without any specific tag manipulation. It's best suited for scenarios where the goal is to extract human-readable text without needing to manipulate specific HTML elements.\n",
    "    4. [Text Splitters](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/): Split up text into chunks. \n",
    "        - Common choice: [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/) ( [Blog : Understanding RecursiveCharacterTextSplitter](https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846) )\n",
    "        - [Chunk visualization](https://chunkviz.up.railway.app)\n",
    "        - [Chunking Strategies for LLM Applications](https://www.pinecone.io/learn/chunking-strategies/)\n",
    "        - Further readings :\n",
    "            - [Sementic Chunker : Langchain - How to split text based on semantic similarity](https://python.langchain.com/docs/how_to/semantic-chunker/)   \n",
    "            - [How Chunk Sizes Affect Semantic Retrieval Results](https://ai.plainenglish.io/investigating-chunk-size-on-semantic-results-b465867d8ca1)\n",
    "            - [5 Levels of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb) - â˜…\n",
    "    5. [Embeddings Models](https://python.langchain.com/docs/how_to/embed_text/)\n",
    "        - Common choice: OpenAIEmbedding ( paid, better to use cache ), uggingFace(OpenSource; BGE, Mistral)\n",
    "            - [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings#what-are-embeddings), [Huggingface Embeddings Benchmark](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "        - Cache: [Caching](https://python.langchain.com/docs/how_to/caching_embeddings/), [LocalFileStore](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html), [CacheBacekdEmbeddings](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html)\n",
    "    \n",
    "    6. [Vector Store](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/):\n",
    "        - Common choise: Local: Chroma, FAISS(For us, FAISS can be a good choice ) / Cloud - Pinecone, Weaviate, ElasticSearch / etc - Lance, Qdrant(for asynchronous operations)\n",
    "        - Vector store queries\n",
    "            - Similarity search / Similarity search by vector / Maximum marginal releance search / Asynchronous operations \n",
    "            - Possible issue: the versions of two methods (```.embed_documents```, ```.embed_query```) might differ due to updates of embedding models(version control needed)\n",
    "        - [TODO] Understanding Indexing of vector store\n",
    "    7. [TODO] [Retrievers Explanation](https://python.langchain.com/v0.1/docs/modules/data_connection/) / [Retrievers](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/) : A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well. Retrievers accept a string query as input and return a list of Document's as output.\n",
    "        - [TODO] read [5 Levels of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb) \n",
    "        - Eval Framework ([langchain evals](https://python.langchain.com/docs/guides/evaluation/) / [llama index evals](https://docs.llamaindex.ai/en/stable/module_guides/evaluating/) / [ragas evals](https://github.com/explodinggradients/ragas) ) \n",
    "\n",
    "- [Research Automation](https://python.langchain.com/v0.1/docs/use_cases/web_scraping/)\n",
    "- [RAG Architecture](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)    \n",
    "- [Youtebe : RAG & Agentic RAG ](https://www.youtube.com/watch?v=hKfQ-0jLw3I)\n",
    "  \n",
    "#### Further Steps \n",
    "Read carefully and get a grasp of which tools to use before I proceed \n",
    "- [Agent Approaches: Plan-Execute Agents](https://blog.langchain.dev/planning-agents/), [structured chat](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/structured_chat/), ReAct( [Paper: ReAct](https://arxiv.org/abs/2210.03629), [Blog: ReAct](https://dottxt-ai.github.io/outlines/latest/cookbook/react_agent/), [How to create a ReAct agent from scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/) ), [Tagging](https://python.langchain.com/docs/tutorials/classification/), schema & function design([tool calling/binding](https://python.langchain.com/docs/concepts/tool_calling/))   \n",
    "- Multi Agent Approaches: LangGraph([A Comprehensive Guide about LangGraph](https://www.ionio.ai/blog/a-comprehensive-guide-about-langgraph-code-included)), Autogen ( Simple Version )\n",
    "- Complementary Tools: BertTopics   \n",
    "- Implement in Kedro / Streamlit \n",
    "\n",
    "#### Optional references\n",
    "- [outlines](https://github.com/dottxt-ai/outlines)  \n",
    "- [Langsmith Prompt Library](https://smith.langchain.com/hub) / [OpenAI - Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)    \n",
    "\n",
    "##### etc \n",
    "[Tool List](https://python.langchain.com/v0.1/docs/integrations/tools/)    \n",
    "[Langchain setup](https://python.langchain.com/v0.1/docs/get_started/installation/)    \n",
    "[Paper: Adaptive-RAG ( Routing )](https://arxiv.org/abs/2403.14403)    \n",
    "[Paper: Corrective-RAG ( Fallback )](https://arxiv.org/abs/2401.15884)  \n",
    "[Paper: Self-RAG ( Self Corretion)](https://arxiv.org/abs/2310.11511)  \n",
    "[Paper: RAPTOR - For really long texts](https://www.youtube.com/watch?v=gcdkISrpMCA)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crawl HTML files and inner URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_companies = [ { 'name' : 'AXA Germany', 'url' : 'https://www.axa.de' },\n",
    "              { 'name' : 'HUK-COBURG', 'url' : 'https://www.huk.de' },\n",
    "              { 'name' : 'Generali', 'url' : 'https://www.generali.de' } \n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse, quote\n",
    "\n",
    "def crawl_company_websites(companies, output_dir='crawls', max_pages=200):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    crawl_results = []\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    for company in companies:\n",
    "        company_name = company['name'].lower().replace(' ', '_')\n",
    "        company_dir = os.path.join(output_dir, company_name)\n",
    "        os.makedirs(company_dir, exist_ok=True)\n",
    "\n",
    "        start_url = company['url']\n",
    "        visited_urls = set()\n",
    "        to_visit = [start_url]\n",
    "        pages_crawled = 0\n",
    "\n",
    "        try:\n",
    "            while to_visit and pages_crawled < max_pages:\n",
    "                url = to_visit.pop(0)\n",
    "                if url in visited_urls:\n",
    "                    continue\n",
    "\n",
    "                response = requests.get(url, headers=headers)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                page_filename = generate_filename_from_url(url)\n",
    "                page_path = os.path.join(company_dir, page_filename)\n",
    "                \n",
    "                \n",
    "                with open(page_path, 'w', encoding='utf-8') as file:\n",
    "                    file.write(response.text)\n",
    "\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                visited_urls.add(url)\n",
    "                pages_crawled += 1\n",
    "\n",
    "                for link in soup.find_all('a', href=True):\n",
    "                    full_url = urljoin(url, link['href'])\n",
    "                    if is_internal_link(start_url, full_url) and full_url not in visited_urls:\n",
    "                        to_visit.append(full_url)\n",
    "                        \n",
    "            # added url_list for loader experiment.\n",
    "            crawl_results.append({'company': company['name'], 'pages_crawled': pages_crawled, 'output_dir': company_dir, 'url_list': list(visited_urls)})\n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling {company['name']}: {e}\")\n",
    "            # added url_list \n",
    "            crawl_results.append({'company': company['name'], 'pages_crawled': pages_crawled, 'output_dir': None, 'error': str(e), 'url_list': list(visited_urls)})\n",
    "\n",
    "        \n",
    "    return crawl_results\n",
    "\n",
    "def is_internal_link(base_url, test_url):\n",
    "    base_domain = urlparse(base_url).netloc\n",
    "    test_domain = urlparse(test_url).netloc\n",
    "    return base_domain == test_domain\n",
    "\n",
    "def generate_filename_from_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    path = parsed_url.path if parsed_url.path else \"home\"\n",
    "    path = path.strip(\"/\").replace(\"/\", \"_\")\n",
    "    query = parsed_url.query\n",
    "    if query:\n",
    "        path += \"_\" + quote(query, safe=\"\")\n",
    "    filename = f\"{path}.html\"\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For experiment : adjust the max_pages\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m crawl_results \u001b[38;5;241m=\u001b[39m \u001b[43mcrawl_company_websites\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_companies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mcrawl_company_websites\u001b[0;34m(companies, output_dir, max_pages)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m visited_urls:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     33\u001b[0m page_filename \u001b[38;5;241m=\u001b[39m generate_filename_from_url(url)\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For experiment : adjust the max_pages\n",
    "crawl_results = crawl_company_websites(input_companies, max_pages=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'AXA Germany',\n",
       " 'pages_crawled': 200,\n",
       " 'output_dir': 'crawls/axa_germany',\n",
       " 'url_list': ['https://www.axa.de/kontakt/formulare-download',\n",
       "  'https://www.axa.de/karriere/new-way-of-working',\n",
       "  'https://www.axa.de/pk/kfz/p/motorradversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/kautionsversicherung',\n",
       "  'https://www.axa.de/site/axa-de/get/documents_E-1395595287/axade/medien/medien/axa-social-media/gewinnspiel-teilnahmebedingungen-social-media-axa-konzern-ag.pdf',\n",
       "  'https://www.axa.de/pk/gesundheit/r/pflegeratgeber',\n",
       "  'https://www.axa.de/schadenservice-360/schadenmeldung',\n",
       "  'https://www.axa.de/pk/gesundheit/s/gesundheitsservice',\n",
       "  'https://www.axa.de/geschaeftskunden/gastronomie',\n",
       "  'https://www.axa.de/pk/altersvorsorge/p/betriebliche-altersvorsorge',\n",
       "  'https://www.axa.de/presse/pm-axa-partner-uefa-womens-euro-2025',\n",
       "  'https://www.axa.de/presse/pm-fondsrente-justinvest',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/verkehrsrechtsschutz',\n",
       "  'https://www.axa.de/wir-ueber-uns/auszeichnungen',\n",
       "  'https://www.axa.de/geschaeftskunden/finanzierungsloesungen/firmenleasing',\n",
       "  'https://www.axa.de/karriere/ausbildung-duales-studium/duales-studium-bachelor-risk-insurance',\n",
       "  'https://www.axa.de/pk/existenzsicherung/p/sterbegeld-versicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/industrie-haftpflichtversicherung#anker7855200',\n",
       "  'https://www.axa.de/geschaeftskunden/it-unternehmen',\n",
       "  'https://www.axa.de/pk/haus-wohnung/p/baufinanzierung',\n",
       "  'https://www.axa.de/karriere/bewerbungstipps',\n",
       "  'https://www.axa.de/karriere/ausbildung-duales-studium/duales-studium-bachelor-informatik',\n",
       "  'https://www.axa.de/wir-ueber-uns/auszeichnungen/tests-produkte-und-services',\n",
       "  'https://www.axa.de/service-apps',\n",
       "  'https://www.axa.de/geschaeftskunden/zusatzinformationen-buergschaft-kaution',\n",
       "  'https://www.axa.de/karriere/jobs-data',\n",
       "  'https://www.axa.de/presse/pm-geldanlageloesung-investnow',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/von-herz-zu-herz',\n",
       "  'https://www.axa.de/karriere/ausbildung-duales-studium',\n",
       "  'https://www.axa.de/geschaeftskunden/finanzierungsloesungen/factoring',\n",
       "  'https://www.axa.de/geschaeftskunden/it-haftpflicht',\n",
       "  'https://www.axa.de/pk/existenzsicherung/p/risikolebensversicherung',\n",
       "  'https://www.axa.de/pk/haus-wohnung/r/haus-wohnung-ratgeber#anker24066235',\n",
       "  'https://www.axa.de/versicherungslexikon',\n",
       "  'https://www.axa.de/geschaeftskunden/inhaltsversicherung',\n",
       "  'https://www.axa.de/karriere/erfahrungsbericht-finance',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/haus-grundbesitzerhaftpflicht',\n",
       "  'https://www.axa.de/pk/haus-wohnung/s/schadenservice-haus',\n",
       "  'https://www.axa.de/wir-ueber-uns/konzernvorstand-und-aufsichtsrat',\n",
       "  'https://www.axa.de/karriere/erfahrungsbericht-data-management',\n",
       "  'https://www.axa.de/pk/kfz/p/oldtimer-versicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns/weltweit',\n",
       "  'https://www.axa.de/karriere/erfahrungsbericht-stipendiatin-diversity',\n",
       "  'https://www.axa.de/pk/kfz/p/lieferwagen-versicherung',\n",
       "  'https://www.axa.de/presse/mediathek/bilder',\n",
       "  'https://www.axa.de/site/axade/redirect/Selfservice-Kontakt',\n",
       "  'https://www.axa.de/geschaeftskunden/landwirtschaft',\n",
       "  'https://www.axa.de/pk/gesundheit/p/pflegezusatzversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/veranstalterhaftpflichtversicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit',\n",
       "  'https://www.axa.de/presse/mediathek/studien-und-forschung/future-risks-report-2023#anker25592699',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/kunstsammlung',\n",
       "  'https://www.axa.de/presse/mediathek/dossiers',\n",
       "  'https://www.axa.de/geschaeftskunden/kontakt-buergschaft-kaution',\n",
       "  'https://www.axa.de/pk/altersvorsorge/p/vermoegenswirksame-leistungen',\n",
       "  'https://www.axa.de/karriere/bock-auf-neues#anker12227672_makingof',\n",
       "  'https://www.axa.de/site/axa-de/redirect/MyAxaLogin?AKTIONSCODE=14015D',\n",
       "  'https://www.axa.de/karriere/vertriebskarriere',\n",
       "  'https://www.axa.de/pk/haus-wohnung/p/bausparvertrag',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebsschliessungsversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/r/ratgeber-gesund-leben#anker24473474',\n",
       "  'https://www.axa.de/karriere/jobs-consulting-strategie',\n",
       "  'https://www.axa.de/pk/geldanlage',\n",
       "  'https://www.axa.de/wir-ueber-uns/historie-und-fakten',\n",
       "  'https://www.axa.de/geschaeftskunden/industrie-haftpflichtversicherung',\n",
       "  'https://www.axa.de/vertriebspartner',\n",
       "  'https://www.axa.de/geschaeftskunden',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/wasserschaden-versicherung',\n",
       "  'https://www.axa.de/pk/existenzsicherung',\n",
       "  'https://www.axa.de/karriere/trainee',\n",
       "  'https://www.axa.de/geschaeftskunden/profi-schutz-absicherung',\n",
       "  'https://www.axa.de/pk/haus-wohnung/r/haus-wohnung-ratgeber',\n",
       "  'https://www.axa.de/kontakt/adressen',\n",
       "  'https://www.axa.de/pk/gesundheit/r/ratgeber-krankenversicherung',\n",
       "  'https://www.axa.de/karriere/duale-karriere-im-para-sport#anker25428987',\n",
       "  'https://www.axa.de/pk/gesundheit/s/online-arzt',\n",
       "  'https://www.axa.de/pk/existenzsicherung/p/existenzschutzversicherung',\n",
       "  'https://www.axa.de/karriere/stellenboerse-axa',\n",
       "  'https://www.axa.de/pk/gesundheit',\n",
       "  'https://www.axa.de/geschaeftskunden/internationale-versicherungsprogramme',\n",
       "  'https://www.axa.de/karriere/kontakt-recruiter',\n",
       "  'https://www.axa.de/karriere',\n",
       "  'https://www.axa.de/pk/kfz/p/roller-versicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/berufshaftpflicht',\n",
       "  'https://www.axa.de/geschaeftskunden/vermoegensschadenhaftpflicht',\n",
       "  'https://www.axa.de/geschaeftskunden/kautionsversicherung#anker16105305',\n",
       "  'https://www.axa.de/geschaeftskunden/autoinhaltsversicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/corporate-social-responsibility',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/nachhaltige-kapitalanlage',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/tierhalter-haftpflicht',\n",
       "  'https://www.axa.de/pk/haftpflicht/r/haftpflichtversicherung-ratgeber',\n",
       "  'https://www.axa.de/pk/gesundheit/p/auslandskrankenversicherung',\n",
       "  'https://www.axa.de/myaxa-kundenportal',\n",
       "  'https://www.axa.de/kontakt/servicenummern',\n",
       "  'https://www.axa.de/pk/kfz/r/kfz-ratgeber',\n",
       "  'https://www.axa.de/karriere/onboarding-neuer-mitarbeiter',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/rechtsschutz',\n",
       "  'https://www.axa.de/pk/altersvorsorge/p/private-rentenversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/p/ambulante-zusatzversicherung',\n",
       "  'https://www.axa.de/karriere/executive-assistant',\n",
       "  'https://www.axa.de/geschaeftskunden/luftfahrtversicherung',\n",
       "  'https://www.axa.de/pk/existenzsicherung/p/berufsunfaehigkeitsversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/s/meine-gesundheit',\n",
       "  'https://www.axa.de/pk/gesundheit/p/zahnzusatzversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/bau',\n",
       "  'https://www.axa.de/pk/haftpflicht',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/umgang-mit-personenbezogenen-daten',\n",
       "  'https://www.axa.de/geschaeftskunden/mitarbeiterabsicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns/daten-und-publikationen',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/bauherrenhaftpflicht',\n",
       "  'https://www.axa.de/geschaeftskunden/bauleistungsversicherung',\n",
       "  'https://www.axa.de/karriere/bock-auf-neues',\n",
       "  'https://www.axa.de/karriere/unternehmenskultur',\n",
       "  'https://www.axa.de/home',\n",
       "  'https://www.axa.de/pk/haus-wohnung',\n",
       "  'https://www.axa.de/nutzungshinweise',\n",
       "  'https://www.axa.de/kontakt/beschwerdemanagement',\n",
       "  'https://www.axa.de/',\n",
       "  'https://www.axa.de/karriere/diversity-inclusion',\n",
       "  'https://www.axa.de/pk/haftpflicht/p/private-haftpflichtversicherung',\n",
       "  'https://www.axa.de/altersvorsorge-ratgeber',\n",
       "  'https://www.axa.de/pk/kfz',\n",
       "  'https://www.axa.de/pk/gesundheit/p/reiseversicherung',\n",
       "  'https://www.axa.de/presse/mediathek/daten-und-fakten',\n",
       "  'https://www.axa.de/geschaeftskunden/elektronikversicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/nachhaltigkeit-versicherungsgeschaeft',\n",
       "  'https://www.axa.de/pk/kfz/p/e-scooter-versicherung',\n",
       "  'https://www.axa.de/pk/haus-wohnung/p/gebaeudeversicherung',\n",
       "  'https://www.axa.de/absicherung-selbststaendige',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebsgebaeudeversicherung',\n",
       "  'https://www.axa.de/presse/mediathek/studien-und-forschung/mental-health-report-2022',\n",
       "  'https://www.axa.de/pk/kfz/p/kfz-versicherung',\n",
       "  'https://www.axa.de',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebliche-gruppenunfallversicherung',\n",
       "  'https://www.axa.de/karriere/bewerbung-faq',\n",
       "  'https://www.axa.de/karriere/praktikum-studenten',\n",
       "  'https://www.axa.de/pk/haus-wohnung/p/hausratversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/industrie-sachversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/ertragsausfallversicherung',\n",
       "  'https://www.axa.de/site/axade/redirect/Selfservice-Kontakt?AKTIONSCODE=14015D',\n",
       "  'https://www.axa.de/geschaeftskunden/kontakt-buergschaft-kaution#anker16105828',\n",
       "  'https://www.axa.de/geschaeftskunden/vertrauensschadenversicherung',\n",
       "  'https://www.axa.de/form/karriere?AKTIONSCODE=14015D',\n",
       "  'https://www.axa.de/kontakt#anker14244724',\n",
       "  'https://www.axa.de/geschaeftskunden/montageversicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/rechtsschutzversicherung',\n",
       "  'https://www.axa.de/wir-ueber-uns/nachhaltigkeit/umweltschutz',\n",
       "  'https://www.axa.de/karriere/erfahrungsbericht-onboarding-praktikantin',\n",
       "  'https://www.axa.de/pk/gesundheit/p/krankentagegeld-versicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/cyber-versicherung',\n",
       "  'https://www.axa.de/geschaeftskunden/verkehrshaftungsversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/s/pkv-privatpatient-leitfaden',\n",
       "  'https://www.axa.de/medien',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebliche-krankenversicherung',\n",
       "  'https://www.axa.de/pk/existenzsicherung/r/existenzsicherung-ratgeber',\n",
       "  'https://www.axa.de/geschaeftskunden/internationale-krankenversicherung',\n",
       "  'https://www.axa.de/axa-social-media',\n",
       "  'https://www.axa.de/pk/gesundheit/s/pflegewelt',\n",
       "  'https://www.axa.de/wir-ueber-uns/auszeichnungen/kundenfeedback',\n",
       "  'https://www.axa.de/karriere/erfahrungsberichte-mitarbeitende',\n",
       "  'https://www.axa.de/presse/mediathek/studien-und-forschung',\n",
       "  'https://www.axa.de/site/axa-de/get/documents_E-1094684217/axade/medien/geschaeftskunden/branchen/uebersicht- branchen/broschuere-geschaeftskunden-branchen.pdf',\n",
       "  'https://www.axa.de/geschaeftskunden/services-fuer-geschaeftskunden',\n",
       "  'https://www.axa.de/geschaeftskunden/waldversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/r/ratgeber-gesund-leben',\n",
       "  'https://www.axa.de/geschaeftskunden/praxisausfallversicherung',\n",
       "  'https://www.axa.de/pk/haftpflicht/r/haftpflichtversicherung-ratgeber#anker25442399',\n",
       "  'https://www.axa.de/wir-ueber-uns/gesellschaften',\n",
       "  'https://www.axa.de/pk/haus-wohnung/p/elementarversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/p/krankenhauszusatzversicherung',\n",
       "  'https://www.axa.de/pk/gesundheit/s/symptom-check',\n",
       "  'https://www.axa.de/pk/altersvorsorge',\n",
       "  'https://www.axa.de/karriere/karrieremesse-events',\n",
       "  'https://www.axa.de/geschaeftskunden/kfz-flottenversicherung',\n",
       "  'https://www.axa.de/datenschutz',\n",
       "  'https://www.axa.de/geschaeftskunden/transportversicherung',\n",
       "  'https://www.axa.de/freundewerben',\n",
       "  'https://www.axa.de/tarif-und-angebotsuebersicht',\n",
       "  'https://www.axa.de/pk/existenzsicherung/p/unfallversicherung',\n",
       "  'https://www.axa.de/pk/kfz/s/schadenservice-auto',\n",
       "  'https://www.axa.de/wir-ueber-uns/corporate-governance',\n",
       "  'https://www.axa.de/karriere/ausbildung-duales-studium/ausbildung-kaufmann-versicherungen-finanzen',\n",
       "  'https://www.axa.de/presse',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebshaftpflicht',\n",
       "  'https://www.axa.de/pk/kfz/p/elektroauto-versicherung',\n",
       "  'https://www.axa.de/karriere/mitarbeitervorteile',\n",
       "  'https://www.axa.de/geschaeftskunden/betriebliche-altersversorgung',\n",
       "  'https://www.axa.de/geschaeftskunden/maschinenversicherung',\n",
       "  'https://www.axa.de/kontakt',\n",
       "  'https://www.axa.de/pk/gesundheit/p/private-krankenversicherung',\n",
       "  'https://www.axa.de/karriere/jobs-it',\n",
       "  'https://www.axa.de/presse/mediathek/audio',\n",
       "  'https://www.axa.de/karriere/jobs-finance',\n",
       "  'https://www.axa.de/karriere/entwicklungsperspektiven',\n",
       "  'https://www.axa.de/pk/kfz/r/kfz-ratgeber#anker24157719',\n",
       "  'https://www.axa.de/impressum',\n",
       "  'https://www.axa.de/presse/mediathek/studien-und-forschung/mental-health-report-2023',\n",
       "  'https://www.axa.de/site/axa-de/get/documents_E-1511147583/axade/medien/ueber axa/wir-ueber-uns/beteiligungsstruktur-axa-konzern.pdf',\n",
       "  'https://www.axa.de/karriere/ausbildung-duales-studium/ausbildung-kaufmann-digitalisierungsmanagement']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform\n",
    "[Transformer](https://python.langchain.com/docs/integrations/document_transformers/)\n",
    "- Example) [HTML2Text](https://python.langchain.com/v0.1/docs/integrations/document_transformers/html2text/) : HTML2Text provides a straightforward conversion of HTML content into plain text (with markdown-like formatting) without any specific tag manipulation. It's best suited for scenarios where the goal is to extract human-readable text without needing to manipulate specific HTML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "def transform_html_to_plain_text(output_dir='cleansed') -> Dict[str, List[Document]] :\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    docs_transformed = {}\n",
    "    html_document_obejcts = get_document_objects() \n",
    "\n",
    "    # define transformer\n",
    "    html2text = Html2TextTransformer()\n",
    "\n",
    "    for company, document_list in html_document_obejcts.items():\n",
    "        company_dir = os.path.join(output_dir, company)\n",
    "        os.makedirs(company_dir, exist_ok=True)\n",
    "\n",
    "        # trnasform documents \n",
    "        docs_transformed[company] = html2text.transform_documents(document_list) \n",
    "        \n",
    "        # save cleansed html files\n",
    "        for i, doc_transformed in enumerate(docs_transformed[company]):\n",
    "            page_path = os.path.join(company_dir, company + \"_cleansed_\" + str(i) + \".txt\")\n",
    "            with open(page_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(doc_transformed.page_content)\n",
    "        \n",
    "    return docs_transformed\n",
    "\n",
    "\n",
    "def get_document_objects(input_dir='crawls') -> Dict[str, List[Document]] :\n",
    "    # Define transformer\n",
    "    html2text = Html2TextTransformer()\n",
    "\n",
    "    # Dictionary to store the parsed HTML content for each company\n",
    "    html_document_obejcts = {}\n",
    "\n",
    "    # Loop through each folder inside company_crawled_data\n",
    "    for company in os.listdir(input_dir):\n",
    "        company_folder = os.path.join(input_dir, company)\n",
    "        \n",
    "        # Check if it is a directory\n",
    "        if os.path.isdir(company_folder):\n",
    "            html_document_obejcts[company] = []\n",
    "            \n",
    "            # Loop through HTML files in the company's folder\n",
    "            for html_file in os.listdir(company_folder):\n",
    "                file_path = os.path.join(company_folder, html_file)\n",
    "                \n",
    "                # Ensure it's an HTML file\n",
    "                if html_file.endswith(\".html\"):\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        raw_html = file.read()\n",
    "                        # Create a Document object for each HTML file\n",
    "                        document = Document(page_content=raw_html, metadata={\"source\": file_path})\n",
    "                        html_document_obejcts[company].append(document)\n",
    "\n",
    "    return html_document_obejcts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_docs = transform_html_to_plain_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- generali ---\n",
      "  * Privatkunden \n",
      "  * GeschÃ¤ftskunden \n",
      "\n",
      "  * Journal \n",
      "  * Berater finden \n",
      "  * Service & Kontakt \n",
      "\n",
      "Suchen\n",
      "\n",
      "  * Rundum-Schutz\n",
      "  * Fahrzeug & Zuhause\n",
      "  * Gesundheit & Freizeit\n",
      "  * Recht & Haftung\n",
      "  * Vorsorge & Finanzen\n",
      "\n",
      "Rundum-Schutz\n",
      "\n",
      "  * VermÃ¶genssicherungspolice \n",
      "  * VermÃ¶gensaufbau & Sicherheitsplan \n",
      "  * Mein Zukunftsplan \n",
      "  * Mein Pflegeschutz \n",
      "\n",
      "Young Line\n",
      "\n",
      "  * Young & Drive \n",
      "  * Young & Home \n",
      "  * Young & Life \n",
      "  * Young & Law \n",
      "  * VermÃ¶gensaufbau4you \n",
      "\n",
      "**VermÃ¶genssicherungspolice**  \n",
      "Rundum geschÃ¼tzt durchs Leben\n",
      "\n",
      "mehr erfahren\n",
      "\n",
      "Fahrzeug\n",
      "\n",
      "  * Kfz-Versicherung \n",
      "  * Kfz-Schutzbrief \n",
      "  * Young & Drive \n",
      "  * Elektro-Fahrzeug \n",
      "  * Digitale Pannenhilfe \n",
      "  * Fahrer-MobilitÃ¤tsschutz \n",
      "  * Oldtimer Optimal \n",
      "  * Motorradversicherung \n",
      "  * Moped & E-Scooter \n",
      "\n",
      "Zuhause\n",
      "\n",
      "  * Hausratversicherung \n",
      "  * WohngebÃ¤udeversicherung \n",
      "  * Glasversicherung \n",
      "  * Haus- und Wohnungsschutzbrief \n",
      "  * Konto- und Finanzschutzbrief \n",
      "  * Photovoltaikversicherung \n",
      "  * Kunstversicherung \n",
      "  * Bauversicherung \n",
      "\n",
      "**Kfz-Versich\n",
      "--- axa_germany ---\n",
      "Bitte aktivieren Sie JavaScript in den Browser-Einstellungen, um diese Seite\n",
      "nutzen zu konnen.\n",
      "\n",
      "Privatkunden GeschÃ¤ftskunden Ãœber AXA Karriere Medien My Axa Login Meine\n",
      "Gesundheit Login Kontakt\n",
      "\n",
      "Fahrzeuge Haftpflicht & Recht Haus & Wohnung Gesundheit Vorsorge & VermÃ¶gen\n",
      "Kundenservice\n",
      "\n",
      "Sach- & Ertragsausfall Haftpflicht BÃ¼rgschaften Finanzierung Weitere Produkte\n",
      "Service & Kontakt\n",
      "\n",
      "Das Unternehmen Unsere Verantwortung Unsere Auszeichnungen\n",
      "\n",
      "Warum AXA? Berufsfelder Jobs Tipps & Kontakt Karriere im Vertrieb\n",
      "\n",
      "Pressemitteilungen Mediathek Medienkontakt AXA auf Social Media\n",
      "\n",
      "SuchvorschlÃ¤ge\n",
      "\n",
      "______\n",
      "\n",
      "Fahrzeuge\n",
      "\n",
      "Versicherungsschutz mit maximaler FlexibilitÃ¤t und fÃ¼r hÃ¶chste Fahr-AnsprÃ¼che.\n",
      "\n",
      "Kfz im Ãœberblick\n",
      "\n",
      "Kfz-Versicherung Motorradversicherung Elektroauto-Versicherung\n",
      "Rollerversicherung E-Scooter Versicherung Oldtimer-Versicherung Lieferwagen-\n",
      "Versicherung Verkehrsrechtschutzversicherung schadenservice360Â° Auto Ratgeber\n",
      "Kfz\n",
      "\n",
      "Haftpflicht & Recht\n",
      "\n",
      "Alle Haftpflichtversicherungen bieten einen wich\n",
      "--- huk-coburg ---\n",
      "Zum Hauptinhalt Ã¼berspringen\n",
      "\n",
      "  * Auto & MobilitÃ¤t\n",
      "\n",
      "    * Kfz-Versicherung\n",
      "      * AutoÂ­versicherung\n",
      "      * Telematik Plus\n",
      "      * Elektroautos\n",
      "      * FahranfÃ¤nger-Versicherung\n",
      "      * Oldtimer & Youngtimer\n",
      "      * Lieferwagen-Versicherung\n",
      "      * Ãœbersicht Kfz-Versicherung\n",
      "\n",
      "    * E-Fahrzeuge\n",
      "      * Elektroautos\n",
      "      * E-Scooter-Versicherung\n",
      "      * S-Pedelec-Versicherung\n",
      "      * Ãœbersicht E-Fahrzeuge\n",
      "\n",
      "    * ZweirÃ¤der & Quads\n",
      "      * MopedÂ­versicherung\n",
      "      * E-Scooter-Versicherung\n",
      "      * LeichtÂ­kraftrad-Versicherung\n",
      "      * Motorrad-Versicherung\n",
      "      * Quad-Versicherung\n",
      "      * Ãœbersicht ZweirÃ¤der & Quads\n",
      "\n",
      "    * Zusatzschutz\n",
      "      * Kfz-Schutzbrief\n",
      "      * FahrerschutzÂ­versicherung\n",
      "      * Verkehrsrechtsschutz\n",
      "      * Ãœbersicht Zusatzschutz\n",
      "\n",
      "    * Wohnmobil & AnhÃ¤nger\n",
      "      * Wohnmobil-Versicherung\n",
      "      * Wohnwagen-Versicherung\n",
      "      * AnhÃ¤nger-Versicherung\n",
      "      * Ãœbersicht Wohnmobil & AnhÃ¤nger\n",
      "\n",
      "    * MobilitÃ¤t\n",
      "      * Autoservice\n",
      "      * Autoankauf, Verkauf & Abo\n",
      "      * THG\n"
     ]
    }
   ],
   "source": [
    "for company, document_list in transformed_docs.items():\n",
    "    # Print the first transformed content of each company \n",
    "    print(f\"--- {company} ---\")\n",
    "    print(document_list[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitter\n",
    "[Text Splitters](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/): Split up text into chunks. \n",
    "- Common choice: [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/) ( [Blog : Understanding RecursiveCharacterTextSplitter](https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846) )\n",
    "- [Chunk visualization](https://chunkviz.up.railway.app)\n",
    "- [Chunking Strategies for LLM Applications](https://www.pinecone.io/learn/chunking-strategies/)\n",
    "- Further readings :\n",
    "    - [Sementic Chunker : Langchain - How to split text based on semantic similarity](https://python.langchain.com/docs/how_to/semantic-chunker/)   \n",
    "    - [How Chunk Sizes Affect Semantic Retrieval Results](https://ai.plainenglish.io/investigating-chunk-size-on-semantic-results-b465867d8ca1)\n",
    "    - [Levels of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import Dict, List\n",
    "\n",
    "def split_transformed_documents(transformed_docs, output_dir='split') -> Dict[str, List[Document]] :\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    transformed_docs_split = {}\n",
    "\n",
    "    # Define text_splitter : adjust the granurality to our project\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=256, \n",
    "        chunk_overlap=10,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    \n",
    "    for company, docs in transformed_docs.items():\n",
    "        company_dir = os.path.join(output_dir, company)\n",
    "        os.makedirs(company_dir, exist_ok=True)\n",
    "        \n",
    "        transformed_docs_split[company] = text_splitter.split_documents(docs)\n",
    "\n",
    "        # save cleansed html files\n",
    "        for i, doc_transformed_split in enumerate(transformed_docs_split[company]):\n",
    "            page_path = os.path.join(company_dir, company + \"_split\" + str(i) + \".txt\")\n",
    "            with open(page_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(doc_transformed_split.page_content)\n",
    "        \n",
    "    return transformed_docs_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = split_transformed_documents(transformed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- generali ---\n",
      "length of chunks : 11758\n",
      "* Privatkunden \n",
      "  * GeschÃ¤ftskunden \n",
      "\n",
      "  * Journal \n",
      "  * Berater finden \n",
      "  * Service & Kontakt \n",
      "\n",
      "Suchen\n",
      "\n",
      "  * Rundum-Schutz\n",
      "  * Fahrzeug & Zuhause\n",
      "  * Gesundheit & Freizeit\n",
      "  * Recht & Haftung\n",
      "  * Vorsorge & Finanzen\n",
      "\n",
      "Rundum-Schutz\n",
      "--- axa_germany ---\n",
      "length of chunks : 16552\n",
      "Bitte aktivieren Sie JavaScript in den Browser-Einstellungen, um diese Seite\n",
      "nutzen zu konnen.\n",
      "\n",
      "Privatkunden GeschÃ¤ftskunden Ãœber AXA Karriere Medien My Axa Login Meine\n",
      "Gesundheit Login Kontakt\n",
      "--- huk-coburg ---\n",
      "length of chunks : 17988\n",
      "Zum Hauptinhalt Ã¼berspringen\n",
      "\n",
      "  * Auto & MobilitÃ¤t\n"
     ]
    }
   ],
   "source": [
    "for company, document_list in docs_split.items():\n",
    "    # Print the first 2000 characters of the first transformed content of each company \n",
    "    print(f\"--- {company} ---\")\n",
    "    print(f'length of chunks : {len(docs_split[company])}')\n",
    "    print(document_list[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Embedding & Vector stores\n",
    "[Embeddings Models](https://python.langchain.com/docs/how_to/embed_text/)\n",
    "- Common choice: OpenAIEmbedding ( paid, better to use cache ), uggingFace(OpenSource; BGE, Mistral)\n",
    "    - [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings#what-are-embeddings), [Huggingface Embeddings Benchmark](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "- Cache: [Caching](https://python.langchain.com/docs/how_to/caching_embeddings/), [LocalFileStore](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html), [CacheBacekdEmbeddings](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html)\n",
    "    \n",
    "[Vector Store](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/):\n",
    "- Common choise: Local: Chroma, FAISS(For us, FAISS can be a good choice ) / Cloud - Pinecone, Weaviate, ElasticSearch / Lance, Qdrant(for asynchronous operations)\n",
    "- Vector store queries\n",
    "    - Similarity search / Similarity search by vector / Maximum marginal releance search / Asynchronous operations \n",
    "    - Possible issue: the versions of two methods (```.embed_documents```, ```.embed_query```) might differ due to updates of embedding models(version control needed)\n",
    "- [TODO] Understanding Indexing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores import FAISS \n",
    "\n",
    "\n",
    "def embed_and_store_in_vector_store(docs_split, store_path = './embeddings_cache/'):\n",
    "    # define embeddings model \n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "        # Serialize : embed - cache - store \n",
    "    cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "        underlying_embeddings = embeddings_model, \n",
    "        document_embedding_cache = store, \n",
    "        namespace = embeddings_model.model\n",
    "    )\n",
    "    \n",
    "    for company, doc_split in docs_split.items():\n",
    "        # directory to cache embedded data \n",
    "        store = LocalFileStore(store_path + company +'/')\n",
    "\n",
    "\n",
    "\n",
    "        # Create FAISS vector store from documents using cached embeddings\n",
    "        FAISS_db = FAISS.from_documents(docs_split[company], cached_embedder)\n",
    "        \n",
    "        # Save vector store locally\n",
    "        FAISS_db.save_local('./db/faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embed_and_store_in_vector_store(\u001b[43mdocs_split\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs_split' is not defined"
     ]
    }
   ],
   "source": [
    "embed_and_store_in_vector_store(docs_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra (See the metadata in the last cell)\n",
    "Instead of using the stored html files, load the raw html documents from the fetched urls.  \n",
    "Loaders give rich metadata \n",
    "  \n",
    "[Document Loader](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/): load data from various sources(web sites, databases, YouTube, arXiv) of various types(PDF, HTML, Json, PowerPoint, etc) as a list of [```document objects```](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)  \n",
    "- Example: [AsyncChromiumLoader](https://python.langchain.com/docs/integrations/document_loaders/async_chromium/) / [AyncHtmlLoader](https://python.langchain.com/docs/integrations/document_loaders/async_html/) - lightweight, load raw HTML files from a list of URLs concurrently  \n",
    "  \n",
    "**Possibly substitue current crawler and transformer to make use of meta data of documents** :  \n",
    "- spider crawler, FireCrawl(Subpage serach, markdown output ), AzureAIDocumentIntelligenceLoader(different file format supports)   \n",
    "- read [HTML Loader](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/html/), see also [Sementic Chunker : Langchain - How to split text based on semantic similarity](https://python.langchain.com/docs/how_to/semantic-chunker/)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using AsyncChromiumLoader in Jupyter Notebook \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AsyncChromiumLoader, AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain.schema import Document\n",
    "from typing import Dict, List\n",
    "\n",
    "def get_url_list(crawl_results):\n",
    "    url_lists = {}\n",
    "    filter_company_urls = [{'company': item['company'], 'url_list': item['url_list']} for item in crawl_results] \n",
    "    for item in filter_company_urls:\n",
    "        url_lists[item['company']] = item['url_list']\n",
    "    return url_lists\n",
    "\n",
    "# Loader : load html document objects from URL \n",
    "def get_htmls_from_urls(url_lists) -> Dict[str, List[Document]] :\n",
    "    html_docs = {} \n",
    "\n",
    "    for company, url_list in url_lists.items():\n",
    "        # define loader \n",
    "        # loader = AsyncChromiumLoader(urls=url_list)\n",
    "        loader = AsyncHtmlLoader(url_list)\n",
    "        # load data into HTML document objects\n",
    "        docs = loader.load() \n",
    "        html_docs[company] = docs\n",
    "\n",
    "    return html_docs\n",
    "\n",
    "# transform loaded html documents to markdown format\n",
    "def transform_html_to_plain_text_from_urls(html_docs):\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed_url = {}\n",
    "    for company, docs in html_docs.items():\n",
    "        docs_transformed_url[company] = html2text.transform_documents(docs)\n",
    "    \n",
    "    return docs_transformed_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_results = crawl_company_websites(input_companies, max_pages=20) \n",
    "url_lists = get_url_list(crawl_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 20/20 [00:06<00:00,  3.31it/s]\n",
      "Fetching pages: 100%|##########| 20/20 [00:02<00:00,  8.98it/s]\n",
      "Fetching pages: 100%|##########| 20/20 [00:08<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url_lists = get_url_list(crawl_results)\n",
    "html_docs = get_htmls_from_urls(url_lists)\n",
    "# docs_transformed_url = transform_html_to_plain_text_from_urls(html_docs)\n",
    "# transformed_docs_split_url = split_transformed_documents(docs_transformed_url)\n",
    "# embed_and_store_in_vector_store(transformed_docs_split_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXA Germany\n",
      "----mata data----\n",
      "{'source': 'https://www.axa.de/site/axa-de/redirect/MyAxaLogin?AKTIONSCODE=14015D', 'title': 'My AXA Login', 'language': 'de'}\n",
      "----page content----\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"de\">\n",
      "<head>\n",
      "\t<meta name=\"version\" content=\"1.21.0\">\n",
      "    <meta charset=\n",
      "HUK-COBURG\n",
      "----mata data----\n",
      "{'source': 'https://www.huk.de/fahrzeuge/kfz-versicherung/leichtkraftrad-versicherung.html', 'title': 'Leichtkraftrad-Versicherung: Ã¼ber 50 ccm - 125 ccm', 'description': 'Ihre Leichtkraftrad-Versicherung: 80ccm & 125ccm âœ“ Niedrige Kosten - Top Leistung âž¨ Kasko & Haftpflicht âœ“ Jetzt berechnen!', 'language': 'de'}\n",
      "----page content----\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"de\" class=\"no-js no-touchevents \">\n",
      "\t\n",
      "<head>\n",
      "    <meta http-equiv=\"Conte\n",
      "Generali\n",
      "----mata data----\n",
      "{'source': 'https://www.generali.de/', 'title': 'Versicherungen, Vorsorge und VermÃ¶gensaufbau I Generali ', 'description': 'Versicherungen, Vorsorge und VermÃ¶gensaufbau â€“ Informieren Sie sich Ã¼ber unsere Produkte oder nutzen Sie unsere Generali Apps und Services. Jetzt Kontakt aufnehmen und beraten lassen fÃ¼r Ihre Versicherung bei der Generali.', 'language': 'de-DE'}\n",
      "----page content----\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"de-DE\" dir=\"ltr\" class=\"no-js\"\n",
      "      data-hyphenator=\"/resource/themes\n"
     ]
    }
   ],
   "source": [
    "for company, doc in html_docs.items():\n",
    "    print(f'{company}')\n",
    "    print(f'----mata data----')\n",
    "    print(doc[0].metadata)\n",
    "    print(f'----page content----')\n",
    "    print(doc[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tested with a query and it spit the corresponding responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
