# Product Page Filter Notebooks (01_product_classification.ipynb)

## Overview
This repository contains two methods (two cells) for filtering insurance company web pages (HTML files) to identify **product pages**. Both cells rely on [LangChain](https://github.com/hwchase17/langchain) and the OpenAI GPT-4o model to classify each file as a product page or not.

After classification, another cell converts the **filtered HTML** files into **Markdown** format using `langchain_community.document_transformers.Html2TextTransformer` (which requires the `html2text` package).

## Contents

1. **Cell 1** – `Filter_Products_Basic`  
   - Uses a simple user-only prompt (`filter_prompt_v1.txt`).  
   - Creates a consolidated CSV named `report_product_pages_v1.csv`.  
   - Copies identified product pages into `02_binary_products_v1/<company>`.

2. **Cell 2** – `Filter_Products_Refined`  
   - Uses a more refined prompt (`filter_prompt_v2.txt`) that includes a system message and a user message.  
   - Creates `report_product_pages_v2.csv`.  
   - Copies product pages into `02_binary_products_v2/<company>`.

3. **Cell 3** – `HTML-to-Markdown Conversion`  
   - Takes the HTML files from the above two folders and converts them to Markdown, preserving the folder structure.  
   - Outputs these Markdown files to `03_textbinary_products_v1/<company>` and `03_textbinary_products_v2/<company>`.

## Setup

1. **Environment Setup**  
   - Use Python 3.8+ in a virtual environment (recommended).  
   - Install the required dependencies:
     ```bash
     pip install openai langchain html2text
     ```
   - Additionally, if you haven’t installed the community transformers, you may need:
     ```bash
     pip install langchain_community
     ```
   - Set your OpenAI API key in an environment variable:
     ```bash
     export OPENAI_API_KEY="your_api_key_here"
     ```

2. **File/Folder Structure**  
   - `filter_prompt_v1.txt` and `filter_prompt_v2.txt` should be in the same directory as your `.ipynb` notebooks (or adjust file paths accordingly).
   - The input folder for classification is defined as:
     ```
     /Users/umutekingezer/Desktop/NLP_lab/LAB-COMPETITIVE-ANALYSIS/data/01_company_crawled_data
     ```
     Each subfolder inside represents a different company (e.g., `axa`, `ergo`, etc.).
   - The output folders for classification (`02_binary_products_v1` or `02_binary_products_v2`) are automatically created if they don’t exist.  
   - The conversion script then looks in these folders and places Markdown files into `03_textbinary_products_v1` and `03_textbinary_products_v2`.

3. **Running the Cells**  
   - **Cell 1** (`Filter_Products_Basic`): Generates `report_product_pages_v1.csv` and copies product pages to `02_binary_products_v1/<company>`.  
   - **Cell 2** (`Filter_Products_Refined`): Generates `report_product_pages_v2.csv` and copies product pages to `02_binary_products_v2/<company>`.  
   - **Cell 3** (`HTML-to-Markdown Conversion`): Converts `.html` files from `02_binary_products_v1` and `02_binary_products_v2` into `.md` files in `03_textbinary_products_v1` and `03_textbinary_products_v2`.

4. **Outputs**  
   - **CSV Files**:
     - `report_product_pages_v1.csv`
     - `report_product_pages_v2.csv`  
     Each CSV contains three columns:
       1. `company_name`  
       2. `filename`  
       3. `product` (`yes` or `no`)

   - **Copied Product Pages**:
     - `02_binary_products_v1/<company>`  
     - `02_binary_products_v2/<company>`

   - **Markdown Files**:
     - `03_textbinary_products_v1/<company>`  
     - `03_textbinary_products_v2/<company>`


# Insurance Product Data Extraction (02_extract_details.ipynb)

This notebook extracts **product names** and **key details** from insurance product descriptions stored as Markdown files. It uses two different prompt approaches:

1. **Prompt V1** (`extract_full_details_prompt_v1.txt`)  
   - A simpler prompt requesting a basic structure with "Produktname" and bullet-point details.

2. **Prompt V2** (`extract_full_details_prompt_v2.txt`)  
   - A more refined prompt with system/human segmentation and clearer instructions, ensuring better extraction of relevant information.

## Workflow

1. **Prerequisites**  
   - Python 3.8+  
   - A working environment with `langchain` and `openai` installed:
     ```bash
     pip install openai langchain
     ```
   - Ensure you have your OpenAI API key set as an environment variable:
     ```bash
     export OPENAI_API_KEY="your_key"
     ```
   - For each cell, the code references:
     - `03_textbinary_products_v1/` (Output from the earlier HTML-to-Markdown step for V1)
     - `03_textbinary_products_v2/` (Output from the earlier HTML-to-Markdown step for V2)

2. **Notebook Cells**  
   - **Cell 1**: Loads the weaker prompt (`extract_full_details_prompt_v1.txt`), processes all `.md` files in `03_textbinary_products_v1`, and writes a JSON file `report_full_details_v1.json`.  
   - **Cell 2**: Loads the refined prompt (`extract_full_details_prompt_v2.txt`), processes `.md` files in `03_textbinary_products_v2`, and writes `report_full_details_v2.json`.

3. **File Output**  
   - **`report_full_details_v1.json`**  
   - **`report_full_details_v2.json`**  
   Each JSON entry has a structure like:
   ```json
   {
     "some_markdown_file.md": {
       "product_name": "XYZ Haftpflicht",
       "details": [
         "Deckungssumme bis 10 Millionen Euro",
         "Gültig weltweit",
         "Inklusive Rechtsberatung"
       ]
     },
     ...
   }



## Contact
Umut Ekin Gezer
