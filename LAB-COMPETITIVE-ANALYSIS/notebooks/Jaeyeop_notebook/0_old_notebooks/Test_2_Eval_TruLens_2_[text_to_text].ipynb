{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trulens Evaluation \n",
    "- [LangChain Quickstart](https://www.trulens.org/getting_started/quickstarts/langchain_quickstart/#create-rag) \n",
    "- [Text to Text](https://www.trulens.org/getting_started/quickstarts/text2text_quickstart/)\n",
    "- [Feedback Function Implementations](https://www.trulens.org/component_guides/evaluation/feedback_implementations/)  \n",
    "    - [Classification-based](https://www.trulens.org/component_guides/evaluation/feedback_implementations/stock/)  \n",
    "        - [context_relevance_with_cot_reasons](https://www.trulens.org/reference/trulens/providers/openai/#trulens.providers.openai.OpenAI.context_relevance_with_cot_reasons)  \n",
    "        - [context_relevance](https://www.trulens.org/reference/trulens/providers/langchain/provider/#trulens.providers.langchain.provider.Langchain.context_relevance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from trulens.core import Feedback, TruSession\n",
    "from trulens.providers.openai import OpenAI as fOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from typing import List\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables and initialize clients\n",
    "load_dotenv()\n",
    "OpenAI_key = os.getenv(\"OPENAI_API_KEY\")  \n",
    "\n",
    "client = OpenAI()\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path = \"prompts/classification_prompts/\"\n",
    "\n",
    "def read_prompt(prompt_path):\n",
    "    with open(prompt_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "system_input_stage_1 = read_prompt(prompt_path + \"classification_system_stage_1.txt\")\n",
    "human_input_stage_1 = read_prompt(prompt_path + \"classification_human_stage_1.txt\")\n",
    "system_input_stage_2 = read_prompt(prompt_path + \"classification_system_stage_2.txt\")\n",
    "human_input_stage_2 = read_prompt(prompt_path + \"classification_human_stage_2.txt\")\n",
    "system_input_stage_3 = read_prompt(prompt_path + \"classification_system_stage_3.txt\")\n",
    "human_input_stage_3 = read_prompt(prompt_path + \"classification_human_stage_3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class answer_format(BaseModel):\n",
    "    answer : str = Field(description=\"answer to the question\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=OpenAI_key, temperature=0, max_tokens=16384) # gpt-40 max tokens = 16384 \n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=answer_format)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "def llm_standalone(prompt):\n",
    "    system_input_stage_1 = read_prompt(prompt_path + \"classification_system_stage_1.txt\")\n",
    "    df = pd.read_csv('company_data.csv')\n",
    "\n",
    "    stage_1_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_input_stage_1),\n",
    "        (\"user\", prompt)\n",
    "    ])\n",
    "\n",
    "    stage_1_chain = stage_1_prompt | llm | parser    \n",
    "    \n",
    "    all_responses = []\n",
    "    first_row = df.iloc[0]\n",
    "    response = stage_1_chain.invoke({\n",
    "        \"company_name\": first_row['company'],\n",
    "        \"title\": first_row['title'],\n",
    "        \"content\": first_row['content'], \n",
    "        \"format_instructions\": format_instructions\n",
    "    })\n",
    "    all_responses.append(response.answer)\n",
    "    return all_responses\n",
    "\n",
    "prompt_input = human_input_stage_1 \n",
    "prompt_output = llm_standalone(prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I got stuck here\n",
    "- was trying to use ```.on( // plain text data // )```, for example ```Feedback(...).on_input().on( // text // ).on_output()``` to evaluate the relevance of the input and output based on the context.  \n",
    "- failed to find a method\n",
    "    -> implemented it with RAG in Classification notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/lzvh2hfd7nbfj2n6q9k0hb980000gn/T/ipykernel_21112/3974589237.py:3: DeprecationWarning: The `trulens_eval` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval import Feedback, Select\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/lzvh2hfd7nbfj2n6q9k0hb980000gn/T/ipykernel_21112/3974589237.py:4: DeprecationWarning: The `trulens_eval.feedback` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.feedback import OpenAI as fOpenAI\n"
     ]
    }
   ],
   "source": [
    "## Initialize Feedback Function(s)\n",
    "\n",
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import OpenAI as fOpenAI\n",
    "\n",
    "# Initialize OpenAI-based feedback function collection class:\n",
    "fopenai = fOpenAI(model_engine = \"gpt-4o\")\n",
    "\n",
    "# context relevance feedback function\n",
    "f_qs_relevance = Feedback(\n",
    "    fopenai.relevance_with_cot_reasons, name = \"Context Relevance\" \n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instrument the callable for logging with TruLens \n",
    "from trulens.apps.basic import TruBasicApp\n",
    "\n",
    "tru_llm_standalone_recorder = TruBasicApp(\n",
    "    llm_standalone, app_name=\"Happy Bot\", feedbacks=[f_qs_relevance]\n",
    ")\n",
    "\n",
    "with tru_llm_standalone_recorder as recording:\n",
    "    tru_llm_standalone_recorder.app(prompt_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>cost_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_hash_0be59e2df0a8e350b033067e8e916dbe</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruBasicApp\", \"mo...</td>\n",
       "      <td>TruWrapperApp(trulens.apps.basic)</td>\n",
       "      <td>record_hash_8c5972dc4d6e927525d882a4d13ce05d</td>\n",
       "      <td>Here are the definitions of categories and sub...</td>\n",
       "      <td>yes</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_8c5972dc4d6e927525d...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-11-29T07:31:50.515939\", \"...</td>\n",
       "      <td>2024-11-29T07:31:51.498128</td>\n",
       "      <td>Happy Bot</td>\n",
       "      <td>base</td>\n",
       "      <td>0.982039</td>\n",
       "      <td>5862</td>\n",
       "      <td>0.01473</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      app_id  \\\n",
       "0  app_hash_0be59e2df0a8e350b033067e8e916dbe   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruBasicApp\", \"mo...   \n",
       "\n",
       "                                type  \\\n",
       "0  TruWrapperApp(trulens.apps.basic)   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_8c5972dc4d6e927525d882a4d13ce05d   \n",
       "\n",
       "                                               input output tags  \\\n",
       "0  Here are the definitions of categories and sub...    yes    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {'record_id': 'record_hash_8c5972dc4d6e927525d...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-11-29T07:31:50.515939\", \"...   \n",
       "\n",
       "                           ts   app_name app_version   latency  total_tokens  \\\n",
       "0  2024-11-29T07:31:51.498128  Happy Bot        base  0.982039          5862   \n",
       "\n",
       "   total_cost cost_currency  \n",
       "0     0.01473           USD  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_records_and_feedback()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2cf058ce6f479db9a63893d5be820c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.0.163:52475 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)  # open a local streamlit app to explore\n",
    "\n",
    "# stop_dashboard(session) # stop if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Testing Context Relevance Feedback Function \n",
    "- to use on(context) $\\Longrightarrow$ BaseRetriever needed in the application $\\Longleftrightarrow$ RAG  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot find any `BaseRetriever` in app.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \n\u001b[1;32m      4\u001b[0m provider \u001b[38;5;241m=\u001b[39m OpenAI() \n\u001b[0;32m----> 6\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mTruChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m feedback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     Feedback(provider\u001b[38;5;241m.\u001b[39mcontext_relevance)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mon_input()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mon(context)\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/test-en/lib/python3.10/site-packages/trulens/apps/langchain/tru_chain.py:260\u001b[0m, in \u001b[0;36mTruChain.select_context\u001b[0;34m(cls, app)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(retrievers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find any `BaseRetriever` in app.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(retrievers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(retrievers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], MultiQueryRetriever):\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot find any `BaseRetriever` in app."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaeyeopchung/.pyenv/versions/test-en/lib/python3.10/site-packages/trulens/feedback/llm_provider.py:286: UserWarning: No supporting evidence provided. Returning score only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.langchain import TruChain\n",
    "import numpy as np  \n",
    "\n",
    "provider = OpenAI() \n",
    "\n",
    "context = TruChain.select_context(llm_standalone)\n",
    "\n",
    "feedback = (\n",
    "    Feedback(provider.context_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
